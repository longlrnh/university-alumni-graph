"""
B·ªï sung th√™m c√¢u h·ªèi Multi-hop ph·ª©c t·∫°p ƒë·ªÉ ƒë·∫°t 2000+ c√¢u h·ªèi
"""

import json
import random
import pandas as pd
import networkx as nx

print("="*80)
print("B·ªî SUNG C√ÇU H·ªéI MULTI-HOP PH·ª®C T·∫†P")
print("="*80)

# Load existing dataset
with open('benchmark_dataset_multihop_2000.json', 'r', encoding='utf-8') as f:
    dataset = json.load(f)

existing_questions = dataset['questions']
print(f"\nüìä Dataset hi·ªán t·∫°i: {len(existing_questions)} c√¢u h·ªèi")

# Load graph
print("üìä ƒêang load Knowledge Graph...")
nodes_df = pd.read_csv('graph_out/nodes_unified.csv')
edges_df = pd.read_csv('graph_out/edges_unified.csv')

G = nx.DiGraph()
for _, row in nodes_df.iterrows():
    G.add_node(row['id'], title=row['title'], node_type=row['type'])

for _, row in edges_df.iterrows():
    G.add_edge(row['from'], row['to'], relation=row['type'], weight=row.get('weight', 1))

node_to_title = {node: data['title'] for node, data in G.nodes(data=True)}
title_to_node = {data['title']: node for node, data in G.nodes(data=True)}

person_nodes = [n for n, d in G.nodes(data=True) if d['node_type'] == 'person']
uni_nodes = [n for n, d in G.nodes(data=True) if d['node_type'] == 'university']

print(f"‚úÖ Graph loaded")

# =============================================================================
# ADDITIONAL CATEGORY: Path Length Questions (True/False)
# =============================================================================

def generate_path_length_questions(n: int = 100) -> list:
    """
    C√¢u h·ªèi v·ªÅ ƒë·ªô d√†i ƒë∆∞·ªùng ƒëi:
    'The shortest path between X and Y is N hops' - True/False
    """
    print("\n[+] Generating Path Length Questions...")
    questions = []
    
    attempts = 0
    while len(questions) < n and attempts < n * 5:
        attempts += 1
        
        p1, p2 = random.sample(person_nodes, 2)
        title1 = node_to_title[p1]
        title2 = node_to_title[p2]
        
        try:
            path = nx.shortest_path(G, p1, p2)
            actual_hops = len(path) - 1
            
            # Random ƒë√∫ng/sai
            if random.random() < 0.5:
                # C√¢u h·ªèi ƒë√∫ng
                stated_hops = actual_hops
                answer = 'True'
                answer_vi = 'ƒê√∫ng'
            else:
                # C√¢u h·ªèi sai
                stated_hops = actual_hops + random.choice([-1, 1, 2])
                if stated_hops < 1:
                    stated_hops = actual_hops + 1
                answer = 'False'
                answer_vi = 'Sai'
            
            question = {
                'id': len(existing_questions) + len(questions) + 1,
                'category': 'path_length',
                'type': 'true_false',
                'difficulty': 'hard',
                'hops': actual_hops,
                'question': f"The shortest path between {title1} and {title2} is {stated_hops} hops.",
                'question_vi': f"ƒê∆∞·ªùng ƒëi ng·∫Øn nh·∫•t gi·ªØa {title1} v√† {title2} l√† {stated_hops} b∆∞·ªõc.",
                'answer': answer,
                'answer_vi': answer_vi,
                'entity1': title1,
                'entity2': title2,
                'actual_hops': actual_hops,
                'stated_hops': stated_hops,
                'explanation': f"Actual shortest path is {actual_hops} hops"
            }
            
            questions.append(question)
        except:
            continue
    
    print(f"  ‚úÖ Generated {len(questions)} path length questions")
    return questions

# =============================================================================
# ADDITIONAL CATEGORY: Shared Connection Count (MCQ)
# =============================================================================

def generate_shared_connection_mcq(n: int = 100) -> list:
    """
    C√¢u h·ªèi tr·∫Øc nghi·ªám: X v√† Y c√≥ bao nhi√™u m·ªëi k·∫øt n·ªëi chung?
    """
    print("\n[+] Generating Shared Connection MCQ...")
    questions = []
    
    attempts = 0
    while len(questions) < n and attempts < n * 5:
        attempts += 1
        
        p1, p2 = random.sample(person_nodes, 2)
        title1 = node_to_title[p1]
        title2 = node_to_title[p2]
        
        # T√≠nh s·ªë connections chung
        neighbors1 = set(G.successors(p1)) | set(G.predecessors(p1))
        neighbors2 = set(G.successors(p2)) | set(G.predecessors(p2))
        common = neighbors1.intersection(neighbors2)
        
        actual_count = len(common)
        
        if actual_count == 0:
            continue
        
        # T·∫°o choices
        choices_nums = [actual_count]
        
        # Add wrong choices
        for _ in range(3):
            wrong = actual_count + random.randint(-10, 10)
            if wrong < 0:
                wrong = 0
            if wrong not in choices_nums:
                choices_nums.append(wrong)
        
        if len(choices_nums) < 4:
            continue
        
        random.shuffle(choices_nums)
        correct_letter = ['A', 'B', 'C', 'D'][choices_nums.index(actual_count)]
        
        question = {
            'id': len(existing_questions) + len(questions) + 1,
            'category': 'shared_connections',
            'type': 'multiple_choice',
            'difficulty': 'hard',
            'hops': 2,
            'question': f"How many common connections do {title1} and {title2} have?",
            'question_vi': f"{title1} v√† {title2} c√≥ bao nhi√™u m·ªëi k·∫øt n·ªëi chung?",
            'choices': {
                'A': str(choices_nums[0]),
                'B': str(choices_nums[1]),
                'C': str(choices_nums[2]),
                'D': str(choices_nums[3])
            },
            'answer': correct_letter,
            'answer_vi': correct_letter,
            'entity1': title1,
            'entity2': title2,
            'explanation': f"They have {actual_count} common connections"
        }
        
        questions.append(question)
    
    print(f"  ‚úÖ Generated {len(questions)} shared connection questions")
    return questions

# =============================================================================
# Generate additional questions
# =============================================================================

new_questions = []
new_questions.extend(generate_path_length_questions(50))
new_questions.extend(generate_shared_connection_mcq(50))

# Combine
all_questions = existing_questions + new_questions

# Re-index
for i, q in enumerate(all_questions, 1):
    q['id'] = i

# Update statistics
print("\n" + "="*80)
print("TH·ªêNG K√ä DATASET M·ªöI")
print("="*80)

print(f"\nüìä T·ªïng s·ªë c√¢u h·ªèi: {len(all_questions)}")

# By category
categories = {}
for q in all_questions:
    cat = q['category']
    categories[cat] = categories.get(cat, 0) + 1

print("\nüìå Ph√¢n lo·∫°i theo category:")
for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
    print(f"  ‚Ä¢ {cat:25s}: {count:4d} c√¢u h·ªèi")

# By type
types = {}
for q in all_questions:
    qtype = q['type']
    types[qtype] = types.get(qtype, 0) + 1

print("\nüìå Ph√¢n lo·∫°i theo lo·∫°i c√¢u h·ªèi:")
for qtype, count in sorted(types.items()):
    print(f"  ‚Ä¢ {qtype:20s}: {count:4d} c√¢u h·ªèi")

# Multi-hop
hops_dist = {}
for q in all_questions:
    hops = q.get('hops', 0)
    if hops:
        hops_dist[hops] = hops_dist.get(hops, 0) + 1

print("\nüìå Ph√¢n lo·∫°i theo s·ªë b∆∞·ªõc Multi-hop:")
for hops, count in sorted(hops_dist.items()):
    print(f"  ‚Ä¢ {hops}-hop: {count:4d} c√¢u h·ªèi")

# Save
dataset['questions'] = all_questions
dataset['metadata']['total_questions'] = len(all_questions)
dataset['metadata']['categories'] = categories
dataset['metadata']['types'] = types
dataset['metadata']['hops_distribution'] = hops_dist

with open('benchmark_dataset_multihop_2000.json', 'w', encoding='utf-8') as f:
    json.dump(dataset, f, indent=2, ensure_ascii=False)

print("\n" + "="*80)
print("‚úÖ ƒê√É C·∫¨P NH·∫¨T DATASET")
print("="*80)

if len(all_questions) >= 2000:
    print(f"\nüéâ ƒê·∫†T M·ª§C TI√äU: {len(all_questions)} c√¢u h·ªèi (>= 2000)")
else:
    print(f"\n‚ö†Ô∏è  C√≤n thi·∫øu: {2000 - len(all_questions)} c√¢u h·ªèi")

print("="*80)
