"""
Download Qwen 3 0.6B t·ª´ Hugging Face
Chu·∫©n b·ªã model cho chatbot
"""

print("="*80)
print("T·∫¢I QWEN 3 0.6B T·ª™ HUGGING FACE")
print("="*80)

try:
    from transformers import AutoTokenizer, AutoModelForCausalLM
    import torch
    
    print("\nüì¶ Transformers library available")
    print(f"   PyTorch version: {torch.__version__}")
    print(f"   CUDA available: {torch.cuda.is_available()}")
    
    model_name = "Qwen/Qwen2-0.5B-Instruct"
    
    print(f"\nüì• Downloading {model_name}...")
    print("   (This may take a few minutes)")
    
    print("\n   [1/2] Downloading tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    print("   ‚úÖ Tokenizer downloaded")
    
    print("\n   [2/2] Downloading model...")
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        device_map="auto"
    )
    print("   ‚úÖ Model downloaded")
    
    print("\n" + "="*80)
    print("‚úÖ SUCCESSFULLY DOWNLOADED QWEN 2 0.5B")
    print("="*80)
    
    print(f"\nüìä Model Info:")
    print(f"   ‚Ä¢ Model name: {model_name}")
    print(f"   ‚Ä¢ Parameters: ~0.5B (small, efficient)")
    print(f"   ‚Ä¢ Type: Instruction-tuned")
    print(f"   ‚Ä¢ Precision: {'FP16' if torch.cuda.is_available() else 'FP32'}")
    print(f"   ‚Ä¢ Device: {'CUDA (GPU)' if torch.cuda.is_available() else 'CPU'}")
    
    print(f"\nüíæ Model saved at: ~/.cache/huggingface/hub/")
    
    # Test inference
    print("\n" + "="*80)
    print("TEST INFERENCE")
    print("="*80)
    
    prompt = "Barack Obama l√† ai?"
    print(f"\n‚ùì Test prompt: {prompt}")
    
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    with torch.no_grad():
        output = model.generate(**inputs, max_new_tokens=50, temperature=0.7)
    
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    print(f"\nüí¨ Response:\n{response}")
    
    print("\n" + "="*80)
    print("‚úÖ MODEL IS READY TO USE!")
    print("="*80)
    
except ImportError as e:
    print(f"\n‚ùå Error: {e}")
    print("\nüí° Installing required packages...")
    print("   Run: pip install transformers torch")
    
except Exception as e:
    print(f"\n‚ùå Error: {e}")
    print("\nüí° Tips:")
    print("   ‚Ä¢ Check internet connection")
    print("   ‚Ä¢ Ensure sufficient disk space (~2GB)")
    print("   ‚Ä¢ Try: pip install --upgrade transformers")
