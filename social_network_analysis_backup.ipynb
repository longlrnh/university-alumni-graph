{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ec466",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PH√ÅT HI·ªÜN C·ªòNG ƒê·ªíNG (COMMUNITY DETECTION)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# S·ª≠ d·ª•ng Louvain method (greedy modularity optimization)\n",
    "print(\"\\n[Louvain Method - Greedy Modularity Optimization]\")\n",
    "print(\"  ‚Üí Ph√°t hi·ªán c·ªông ƒë·ªìng t·ª´ m·∫°ng...\")\n",
    "\n",
    "from networkx.algorithms import community\n",
    "\n",
    "# Louvain (greedy modularity optimization)\n",
    "communities_louvain = list(community.greedy_modularity_communities(G_undirected))\n",
    "modularity_louvain = community.modularity(G_undirected, communities_louvain)\n",
    "\n",
    "print(f\"‚úì S·ªë c·ªông ƒë·ªìng ph√°t hi·ªán: {len(communities_louvain)}\")\n",
    "print(f\"‚úì Modularity Score: {modularity_louvain:.6f}\")\n",
    "\n",
    "# Ph√¢n t√≠ch c·ªông ƒë·ªìng\n",
    "print(\"\\n[Ph√¢n t√≠ch chi ti·∫øt c·ªông ƒë·ªìng]\")\n",
    "community_stats = []\n",
    "\n",
    "for idx, comm in enumerate(communities_louvain):\n",
    "    comm_nodes = list(comm)\n",
    "    comm_size = len(comm)\n",
    "    \n",
    "    # Lo·∫°i nodes trong c·ªông ƒë·ªìng\n",
    "    node_types_in_comm = defaultdict(int)\n",
    "    for node_id in comm_nodes:\n",
    "        node_type = nodes_df[nodes_df['id'] == node_id]['type'].values[0] if node_id in nodes_df['id'].values else 'unknown'\n",
    "        node_types_in_comm[node_type] += 1\n",
    "    \n",
    "    # L·∫•y top nodes theo degree\n",
    "    subgraph = G_undirected.subgraph(comm_nodes)\n",
    "    top_nodes_in_comm = sorted(subgraph.degree(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    community_stats.append({\n",
    "        'community_id': idx,\n",
    "        'size': comm_size,\n",
    "        'percentage': (comm_size / G_undirected.number_of_nodes() * 100),\n",
    "        'node_types': dict(node_types_in_comm),\n",
    "        'top_nodes': top_nodes_in_comm\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nC·ªông ƒë·ªìng {idx + 1}:\")\n",
    "    print(f\"  ‚Ä¢ K√≠ch th∆∞·ªõc: {comm_size} nodes ({comm_size/G_undirected.number_of_nodes()*100:.2f}%)\")\n",
    "    print(f\"  ‚Ä¢ Lo·∫°i nodes: {dict(node_types_in_comm)}\")\n",
    "    print(f\"  ‚Ä¢ Top 3 nodes:\")\n",
    "    for node_id, degree in top_nodes_in_comm[:3]:\n",
    "        node_title = nodes_df[nodes_df['id'] == node_id]['title'].values[0] if node_id in nodes_df['id'].values else node_id\n",
    "        node_type = nodes_df[nodes_df['id'] == node_id]['type'].values[0] if node_id in nodes_df['id'].values else 'unknown'\n",
    "        print(f\"      - {node_title} [{node_type}] (Degree: {degree})\")\n",
    "\n",
    "# Th·ªëng k√™ c·ªông ƒë·ªìng\n",
    "print(f\"\\n[TH·ªêNG K√ä C·ªòNG ƒê·ªíNG]\")\n",
    "print(f\"K√≠ch th∆∞·ªõc c·ªông ƒë·ªìng:\")\n",
    "sizes = [stat['size'] for stat in community_stats]\n",
    "print(f\"  ‚Ä¢ L·ªõn nh·∫•t: {max(sizes)}\")\n",
    "print(f\"  ‚Ä¢ Nh·ªè nh·∫•t: {min(sizes)}\")\n",
    "print(f\"  ‚Ä¢ Trung b√¨nh: {np.mean(sizes):.1f}\")\n",
    "print(f\"  ‚Ä¢ Trung v·ªã: {np.median(sizes):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d78a0a",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Ph√°t Hi·ªán C·ªông ƒê·ªìng (Community Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4849c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√¨nh ·∫£nh h√≥a x·∫øp h·∫°ng\n",
    "print(\"\\n[H√¨nh ·∫£nh h√≥a X·∫æP H·∫†NG]\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# PageRank\n",
    "pagerank_df = pd.DataFrame(list(top_pagerank), columns=['Node', 'Score'])\n",
    "pagerank_df['Label'] = pagerank_df['Node'].apply(lambda x: nodes_df[nodes_df['id'] == x]['title'].values[0][:20] if x in nodes_df['id'].values else x)\n",
    "axes[0, 0].barh(range(len(pagerank_df)), pagerank_df['Score'], color='#FF6B6B')\n",
    "axes[0, 0].set_yticks(range(len(pagerank_df)))\n",
    "axes[0, 0].set_yticklabels(pagerank_df['Label'], fontsize=9)\n",
    "axes[0, 0].set_xlabel('PageRank Score', fontsize=10)\n",
    "axes[0, 0].set_title('Top 10 Nodes - PageRank', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# Degree Centrality\n",
    "degree_df = pd.DataFrame(list(top_degree), columns=['Node', 'Score'])\n",
    "degree_df['Label'] = degree_df['Node'].apply(lambda x: nodes_df[nodes_df['id'] == x]['title'].values[0][:20] if x in nodes_df['id'].values else x)\n",
    "axes[0, 1].barh(range(len(degree_df)), degree_df['Score'], color='#4ECDC4')\n",
    "axes[0, 1].set_yticks(range(len(degree_df)))\n",
    "axes[0, 1].set_yticklabels(degree_df['Label'], fontsize=9)\n",
    "axes[0, 1].set_xlabel('Degree Centrality Score', fontsize=10)\n",
    "axes[0, 1].set_title('Top 10 Nodes - Degree Centrality', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# Betweenness Centrality\n",
    "betweenness_df = pd.DataFrame(list(top_betweenness), columns=['Node', 'Score'])\n",
    "betweenness_df['Label'] = betweenness_df['Node'].apply(lambda x: nodes_df[nodes_df['id'] == x]['title'].values[0][:20] if x in nodes_df['id'].values else x)\n",
    "axes[1, 0].barh(range(len(betweenness_df)), betweenness_df['Score'], color='#95E1D3')\n",
    "axes[1, 0].set_yticks(range(len(betweenness_df)))\n",
    "axes[1, 0].set_yticklabels(betweenness_df['Label'], fontsize=9)\n",
    "axes[1, 0].set_xlabel('Betweenness Centrality Score', fontsize=10)\n",
    "axes[1, 0].set_title('Top 10 Nodes - Betweenness Centrality', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# Closeness Centrality\n",
    "closeness_df = pd.DataFrame(list(top_closeness), columns=['Node', 'Score'])\n",
    "closeness_df['Label'] = closeness_df['Node'].apply(lambda x: nodes_df[nodes_df['id'] == x]['title'].values[0][:20] if x in nodes_df['id'].values else x)\n",
    "axes[1, 1].barh(range(len(closeness_df)), closeness_df['Score'], color='#F38181')\n",
    "axes[1, 1].set_yticks(range(len(closeness_df)))\n",
    "axes[1, 1].set_yticklabels(closeness_df['Label'], fontsize=9)\n",
    "axes[1, 1].set_xlabel('Closeness Centrality Score', fontsize=10)\n",
    "axes[1, 1].set_title('Top 10 Nodes - Closeness Centrality', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph_out/ranking_algorithms.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì L∆∞u: graph_out/ranking_algorithms.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3dbcf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "THU·∫¨T TO√ÅN X·∫æP H·∫†NG ƒê·ªí TH·ªä (GRAPH RANKING)\n",
      "================================================================================\n",
      "\n",
      "[1. PageRank Ranking]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# PageRank\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[1. PageRank Ranking]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m pagerank_scores \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241m.\u001b[39mpagerank(G)\n\u001b[0;32m      8\u001b[0m top_pagerank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(pagerank_scores\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:\u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 10 nodes theo PageRank:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nx' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"THU·∫¨T TO√ÅN X·∫æP H·∫†NG ƒê·ªí TH·ªä (GRAPH RANKING)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# PageRank\n",
    "print(\"\\n[1. PageRank Ranking]\")\n",
    "pagerank_scores = nx.pagerank(G)\n",
    "top_pagerank = sorted(pagerank_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 nodes theo PageRank:\")\n",
    "for rank, (node_id, score) in enumerate(top_pagerank, 1):\n",
    "    node_title = nodes_df[nodes_df['id'] == node_id]['title'].values[0] if node_id in nodes_df['id'].values else node_id\n",
    "    node_type = nodes_df[nodes_df['id'] == node_id]['type'].values[0] if node_id in nodes_df['id'].values else 'unknown'\n",
    "    print(f\"  {rank:2d}. {node_title:<40} [{node_type:10s}] Score: {score:.6f}\")\n",
    "\n",
    "# Degree Centrality\n",
    "print(\"\\n[2. Degree Centrality Ranking]\")\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 nodes theo Degree Centrality:\")\n",
    "for rank, (node_id, score) in enumerate(top_degree, 1):\n",
    "    node_title = nodes_df[nodes_df['id'] == node_id]['title'].values[0] if node_id in nodes_df['id'].values else node_id\n",
    "    node_type = nodes_df[nodes_df['id'] == node_id]['type'].values[0] if node_id in nodes_df['id'].values else 'unknown'\n",
    "    degree = G.degree(node_id)\n",
    "    print(f\"  {rank:2d}. {node_title:<40} [{node_type:10s}] Score: {score:.6f} (Degree: {degree})\")\n",
    "\n",
    "# Betweenness Centrality\n",
    "print(\"\\n[3. Betweenness Centrality Ranking]\")\n",
    "print(\"  ‚Üí T√≠nh to√°n (c√≥ th·ªÉ t·ªën th·ªùi gian)...\")\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 nodes theo Betweenness Centrality:\")\n",
    "for rank, (node_id, score) in enumerate(top_betweenness, 1):\n",
    "    node_title = nodes_df[nodes_df['id'] == node_id]['title'].values[0] if node_id in nodes_df['id'].values else node_id\n",
    "    node_type = nodes_df[nodes_df['id'] == node_id]['type'].values[0] if node_id in nodes_df['id'].values else 'unknown'\n",
    "    print(f\"  {rank:2d}. {node_title:<40} [{node_type:10s}] Score: {score:.6f}\")\n",
    "\n",
    "# Closeness Centrality (cho largest component)\n",
    "print(\"\\n[4. Closeness Centrality Ranking]\")\n",
    "print(\"  ‚Üí T√≠nh to√°n cho th√†nh ph·∫ßn li√™n th√¥ng l·ªõn nh·∫•t...\")\n",
    "closeness_centrality = nx.closeness_centrality(largest_cc)\n",
    "top_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 nodes theo Closeness Centrality:\")\n",
    "for rank, (node_id, score) in enumerate(top_closeness, 1):\n",
    "    node_title = nodes_df[nodes_df['id'] == node_id]['title'].values[0] if node_id in nodes_df['id'].values else node_id\n",
    "    node_type = nodes_df[nodes_df['id'] == node_id]['type'].values[0] if node_id in nodes_df['id'].values else 'unknown'\n",
    "    print(f\"  {rank:2d}. {node_title:<40} [{node_type:10s}] Score: {score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3c371",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Thu·∫≠t To√°n X·∫øp H·∫°ng ƒê·ªì Th·ªã (PageRank, Degree Centrality, Betweenness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278abfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CH·ª®NG MINH KH√ÅI NI·ªÜM TH·∫æ GI·ªöI NH·ªé (SMALL WORLD)\n",
      "================================================================================\n",
      "\n",
      "[Ph√¢n t√≠ch k·∫øt n·ªëi c·ªông ƒë·ªìng]\n",
      "! ƒê·ªì th·ªã kh√¥ng li√™n th√¥ng (disconnected)\n",
      "  ‚Ä¢ S·ªë th√†nh ph·∫ßn li√™n th√¥ng: 98\n",
      "  ‚Ä¢ Th√†nh ph·∫ßn l·ªõn nh·∫•t: 2055 nodes (95.1%)\n",
      "\n",
      "[T√≠nh to√°n kho·∫£ng c√°ch ng·∫Øn nh·∫•t]\n",
      "  ‚Ä¢ S·ªë th√†nh ph·∫ßn li√™n th√¥ng: 98\n",
      "  ‚Ä¢ Th√†nh ph·∫ßn l·ªõn nh·∫•t: 2055 nodes (95.1%)\n",
      "\n",
      "[T√≠nh to√°n kho·∫£ng c√°ch ng·∫Øn nh·∫•t]\n",
      "‚úì Kho·∫£ng c√°ch ng·∫Øn nh·∫•t trung b√¨nh: 3.3011\n",
      "‚úì Kho·∫£ng c√°ch ng·∫Øn nh·∫•t trung b√¨nh: 3.3011\n",
      "‚úì ƒê∆∞·ªùng k√≠nh c·ªßa m·∫°ng (diameter): 9\n",
      "\n",
      "[H·ªá s·ªë gom c·ª•m (Clustering Coefficient)]\n",
      "‚úì ƒê∆∞·ªùng k√≠nh c·ªßa m·∫°ng (diameter): 9\n",
      "\n",
      "[H·ªá s·ªë gom c·ª•m (Clustering Coefficient)]\n",
      "‚úì H·ªá s·ªë gom c·ª•m trung b√¨nh: 0.456741\n",
      "\n",
      "[So s√°nh v·ªõi Random Graph]\n",
      "‚úì H·ªá s·ªë gom c·ª•m trung b√¨nh: 0.456741\n",
      "\n",
      "[So s√°nh v·ªõi Random Graph]\n",
      "Alumni Network:\n",
      "  ‚Ä¢ Avg. Path Length: 3.3011\n",
      "  ‚Ä¢ Avg. Clustering: 0.456741\n",
      "\n",
      "Random Graph (p=0.024309):\n",
      "  ‚Ä¢ Avg. Path Length: 2.2477\n",
      "  ‚Ä¢ Avg. Clustering: 0.024375\n",
      "\n",
      "[Small World Coefficient œÉ = C/C_random √∑ L/L_random]\n",
      "‚úì œÉ = 12.7590\n",
      "‚úì M·∫°ng n√†y c√≥ t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé (Small World)\n",
      "  ‚Üí C√≥ gom c·ª•m cao (high clustering)\n",
      "  ‚Üí Nh∆∞ng kho·∫£ng c√°ch ng·∫Øn (short paths)\n",
      "Alumni Network:\n",
      "  ‚Ä¢ Avg. Path Length: 3.3011\n",
      "  ‚Ä¢ Avg. Clustering: 0.456741\n",
      "\n",
      "Random Graph (p=0.024309):\n",
      "  ‚Ä¢ Avg. Path Length: 2.2477\n",
      "  ‚Ä¢ Avg. Clustering: 0.024375\n",
      "\n",
      "[Small World Coefficient œÉ = C/C_random √∑ L/L_random]\n",
      "‚úì œÉ = 12.7590\n",
      "‚úì M·∫°ng n√†y c√≥ t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé (Small World)\n",
      "  ‚Üí C√≥ gom c·ª•m cao (high clustering)\n",
      "  ‚Üí Nh∆∞ng kho·∫£ng c√°ch ng·∫Øn (short paths)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CH·ª®NG MINH KH√ÅI NI·ªÜM TH·∫æ GI·ªöI NH·ªé (SMALL WORLD)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[Ph√¢n t√≠ch k·∫øt n·ªëi c·ªông ƒë·ªìng]\")\n",
    "\n",
    "# T√¨m connected components\n",
    "if nx.is_connected(G_undirected):\n",
    "    print(\"‚úì ƒê·ªì th·ªã l√† li√™n th√¥ng (connected)\")\n",
    "    largest_cc = G_undirected\n",
    "    num_components = 1\n",
    "else:\n",
    "    print(\"! ƒê·ªì th·ªã kh√¥ng li√™n th√¥ng (disconnected)\")\n",
    "    components = list(nx.connected_components(G_undirected))\n",
    "    num_components = len(components)\n",
    "    largest_cc = G_undirected.subgraph(max(components, key=len)).copy()\n",
    "    print(f\"  ‚Ä¢ S·ªë th√†nh ph·∫ßn li√™n th√¥ng: {num_components}\")\n",
    "    print(f\"  ‚Ä¢ Th√†nh ph·∫ßn l·ªõn nh·∫•t: {len(largest_cc)} nodes ({len(largest_cc)/G_undirected.number_of_nodes()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n[T√≠nh to√°n kho·∫£ng c√°ch ng·∫Øn nh·∫•t]\")\n",
    "\n",
    "# T√≠nh average shortest path length cho largest connected component\n",
    "if len(largest_cc) > 1:\n",
    "    try:\n",
    "        avg_path_length = nx.average_shortest_path_length(largest_cc)\n",
    "        print(f\"‚úì Kho·∫£ng c√°ch ng·∫Øn nh·∫•t trung b√¨nh: {avg_path_length:.4f}\")\n",
    "    except:\n",
    "        avg_path_length = None\n",
    "        print(\"! Kh√¥ng th·ªÉ t√≠nh (c√≥ th·ªÉ do ƒë·ªì th·ªã kh√¥ng li√™n th√¥ng)\")\n",
    "else:\n",
    "    avg_path_length = 0\n",
    "    print(\"ƒê·ªì th·ªã qu√° nh·ªè ƒë·ªÉ t√≠nh\")\n",
    "\n",
    "# T√≠nh diameter\n",
    "try:\n",
    "    diameter = nx.diameter(largest_cc)\n",
    "    print(f\"‚úì ƒê∆∞·ªùng k√≠nh c·ªßa m·∫°ng (diameter): {diameter}\")\n",
    "except:\n",
    "    diameter = None\n",
    "    print(\"! Kh√¥ng th·ªÉ t√≠nh diameter\")\n",
    "\n",
    "# T√≠nh clustering coefficient\n",
    "print(f\"\\n[H·ªá s·ªë gom c·ª•m (Clustering Coefficient)]\")\n",
    "\n",
    "avg_clustering = nx.average_clustering(G_undirected)\n",
    "print(f\"‚úì H·ªá s·ªë gom c·ª•m trung b√¨nh: {avg_clustering:.6f}\")\n",
    "\n",
    "# So s√°nh v·ªõi random graph\n",
    "print(f\"\\n[So s√°nh v·ªõi Random Graph]\")\n",
    "\n",
    "n_nodes = G_undirected.number_of_nodes()\n",
    "n_edges = G_undirected.number_of_edges()\n",
    "random_prob = (2 * n_edges) / (n_nodes * (n_nodes - 1))\n",
    "\n",
    "G_random = nx.erdos_renyi_graph(n_nodes, random_prob)\n",
    "\n",
    "if nx.is_connected(G_random):\n",
    "    random_avg_path = nx.average_shortest_path_length(G_random)\n",
    "else:\n",
    "    largest_component = max(nx.connected_components(G_random), key=len)\n",
    "    G_random_cc = G_random.subgraph(largest_component).copy()\n",
    "    random_avg_path = nx.average_shortest_path_length(G_random_cc)\n",
    "\n",
    "random_avg_clustering = nx.average_clustering(G_random)\n",
    "\n",
    "print(f\"Alumni Network:\")\n",
    "print(f\"  ‚Ä¢ Avg. Path Length: {avg_path_length:.4f}\")\n",
    "print(f\"  ‚Ä¢ Avg. Clustering: {avg_clustering:.6f}\")\n",
    "\n",
    "print(f\"\\nRandom Graph (p={random_prob:.6f}):\")\n",
    "print(f\"  ‚Ä¢ Avg. Path Length: {random_avg_path:.4f}\")\n",
    "print(f\"  ‚Ä¢ Avg. Clustering: {random_avg_clustering:.6f}\")\n",
    "\n",
    "# Ki·ªÉm tra t√≠nh ch·∫•t Small World\n",
    "sigma = (avg_clustering / random_avg_clustering) / (avg_path_length / random_avg_path) if random_avg_path > 0 else 0\n",
    "print(f\"\\n[Small World Coefficient œÉ = C/C_random √∑ L/L_random]\")\n",
    "print(f\"‚úì œÉ = {sigma:.4f}\")\n",
    "\n",
    "if sigma > 1:\n",
    "    print(\"‚úì M·∫°ng n√†y c√≥ t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé (Small World)\")\n",
    "    print(\"  ‚Üí C√≥ gom c·ª•m cao (high clustering)\")\n",
    "    print(\"  ‚Üí Nh∆∞ng kho·∫£ng c√°ch ng·∫Øn (short paths)\")\n",
    "else:\n",
    "    print(\"! M·∫°ng n√†y KH√îNG c√≥ t√≠nh ch·∫•t Small World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc4cc7a",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Ch·ª©ng Minh Kh√°i Ni·ªám Th·∫ø Gi·ªõi Nh·ªè (Small World)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e186e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] X√¢y d·ª±ng ƒë·ªì th·ªã...\n",
      "‚úì ƒê·ªì th·ªã x√¢y d·ª±ng th√†nh c√¥ng\n",
      "  ‚Ä¢ Nodes: 2162\n",
      "  ‚Ä¢ Edges: 57975\n",
      "  ‚Ä¢ M·∫≠t ƒë·ªô: 0.012409\n",
      "‚úì ƒê·ªì th·ªã x√¢y d·ª±ng th√†nh c√¥ng\n",
      "  ‚Ä¢ Nodes: 2162\n",
      "  ‚Ä¢ Edges: 57975\n",
      "  ‚Ä¢ M·∫≠t ƒë·ªô: 0.012409\n",
      "\n",
      "‚úì Undirected graph: 2162 nodes, 56787 edges\n",
      "\n",
      "‚úì Undirected graph: 2162 nodes, 56787 edges\n"
     ]
    }
   ],
   "source": [
    "# X√¢y d·ª±ng ƒë·ªì th·ªã NetworkX\n",
    "print(\"\\n[+] X√¢y d·ª±ng ƒë·ªì th·ªã...\")\n",
    "\n",
    "# T·∫°o graph t·ª´ edge list\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Th√™m nodes\n",
    "for _, row in nodes_df.iterrows():\n",
    "    G.add_node(row['id'], title=row['title'], node_type=row['type'])\n",
    "\n",
    "# Th√™m edges\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row['from'], row['to'], \n",
    "              relation_type=row['type'], \n",
    "              weight=row.get('weight', 1))\n",
    "\n",
    "print(f\"‚úì ƒê·ªì th·ªã x√¢y d·ª±ng th√†nh c√¥ng\")\n",
    "print(f\"  ‚Ä¢ Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"  ‚Ä¢ Edges: {G.number_of_edges()}\")\n",
    "print(f\"  ‚Ä¢ M·∫≠t ƒë·ªô: {nx.density(G):.6f}\")\n",
    "\n",
    "# Chuy·ªÉn sang undirected graph ƒë·ªÉ ph√¢n t√≠ch c·ªông ƒë·ªìng\n",
    "G_undirected = G.to_undirected()\n",
    "print(f\"\\n‚úì Undirected graph: {G_undirected.number_of_nodes()} nodes, {G_undirected.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad40aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] ƒêang t·∫£i d·ªØ li·ªáu...\n",
      "‚úì ƒê√£ t·∫£i 2162 nodes v√† 66910 edges\n",
      "\n",
      "[NODES THEO LO·∫†I]\n",
      "  ‚Ä¢ person: 1229\n",
      "  ‚Ä¢ university: 842\n",
      "  ‚Ä¢ country: 67\n",
      "  ‚Ä¢ career: 24\n",
      "\n",
      "[EDGES THEO LO·∫†I]\n",
      "  ‚Ä¢ same_birth_country: 39957\n",
      "  ‚Ä¢ link_to: 15319\n",
      "  ‚Ä¢ same_uni: 8707\n",
      "  ‚Ä¢ alumni_of: 1629\n",
      "  ‚Ä¢ same_career: 1298\n"
     ]
    }
   ],
   "source": [
    "# T·∫£i d·ªØ li·ªáu\n",
    "print(\"[+] ƒêang t·∫£i d·ªØ li·ªáu...\")\n",
    "\n",
    "# T·∫£i nodes\n",
    "with open('graph_out/nodes_unified.csv', 'r', encoding='utf-8') as f:\n",
    "    nodes_df = pd.read_csv(f)\n",
    "\n",
    "# T·∫£i edges\n",
    "with open('graph_out/edges_unified.csv', 'r', encoding='utf-8') as f:\n",
    "    edges_df = pd.read_csv(f)\n",
    "\n",
    "print(f\"‚úì ƒê√£ t·∫£i {len(nodes_df)} nodes v√† {len(edges_df)} edges\")\n",
    "\n",
    "# Th·ªëng k√™ nodes theo lo·∫°i\n",
    "print(\"\\n[NODES THEO LO·∫†I]\")\n",
    "node_types = nodes_df['type'].value_counts()\n",
    "for node_type, count in node_types.items():\n",
    "    print(f\"  ‚Ä¢ {node_type}: {count}\")\n",
    "\n",
    "# Th·ªëng k√™ edges theo lo·∫°i\n",
    "print(\"\\n[EDGES THEO LO·∫†I]\")\n",
    "edge_types = edges_df['type'].value_counts()\n",
    "for edge_type, count in edge_types.items():\n",
    "    print(f\"  ‚Ä¢ {edge_type}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4540bdc1",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ T·∫£i v√† Chu·∫©n B·ªã D·ªØ Li·ªáu M·∫°ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859b04f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Th∆∞ vi·ªán ƒë∆∞·ª£c import th√†nh c√¥ng\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Thi·∫øt l·∫≠p font cho Vietnamese\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"‚úì Th∆∞ vi·ªán ƒë∆∞·ª£c import th√†nh c√¥ng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c2295",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Th∆∞ Vi·ªán C·∫ßn Thi·∫øt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1e7f4",
   "metadata": {},
   "source": [
    "# üìä Ph√¢n T√≠ch M·∫°ng X√£ H·ªôi Alumni - Social Network Analysis\n",
    "\n",
    "## M·ª•c ti√™u\n",
    "Ph√¢n t√≠ch m·∫°ng alumni b·∫±ng c√°c thu·∫≠t to√°n n√¢ng cao:\n",
    "1. ‚úì Ch·ª©ng minh kh√°i ni·ªám **th·∫ø gi·ªõi nh·ªè** (Small World)\n",
    "2. ‚úì X·∫øp h·∫°ng nodes b·∫±ng **PageRank** v√† c√°c thu·∫≠t to√°n ƒë·ªì th·ªã\n",
    "3. ‚úì Ph√°t hi·ªán **c·ªông ƒë·ªìng** (Community Detection)\n",
    "4. ‚úì Ph√¢n t√≠ch **ƒë·ªô trung t√¢m** (Centrality Measures)\n",
    "\n",
    "## D·ªØ li·ªáu\n",
    "- **Nodes**: 2,162 (ng∆∞·ªùi, ƒë·∫°i h·ªçc, qu·ªëc gia, ngh·ªÅ)\n",
    "- **Edges**: 66,910 (t·∫•t c·∫£ c√°c m·ªëi quan h·ªá)\n",
    "- **Lo·∫°i m·ªëi quan h·ªá**: same_birth_country, link_to, same_uni, alumni_of, same_career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ed63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"T√ìM T·∫ÆT & K·∫æT LU·∫¨N - PH√ÇN T√çCH M·∫†NG X√É H·ªòI ALUMNI\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n[1. KH√ÅI NI·ªÜM TH·∫æ GI·ªöI NH·ªé (SMALL WORLD)]\")\n",
    "print(f\"  ‚úì Kho·∫£ng c√°ch ng·∫Øn nh·∫•t trung b√¨nh: {avg_path_length:.4f} hops\")\n",
    "if diameter:\n",
    "    print(f\"  ‚úì ƒê∆∞·ªùng k√≠nh m·∫°ng: {diameter}\")\n",
    "print(f\"  ‚úì H·ªá s·ªë gom c·ª•m: {avg_clustering:.6f}\")\n",
    "print(f\"  ‚úì Small World Coefficient (œÉ): {sigma:.4f}\")\n",
    "\n",
    "if sigma > 1:\n",
    "    print(f\"\\n  ‚ûú K·∫æT LU·∫¨N: M·∫°ng Alumni c√≥ t√≠nh ch·∫•t TH·∫æ GI·ªöI NH·ªé\")\n",
    "    print(f\"     - Ng∆∞·ªùi d√πng c√°ch nhau r·∫•t g·∫ßn (avg path ‚âà {avg_path_length:.2f})\")\n",
    "    print(f\"     - Nh∆∞ng c√≥ ƒë·ªô gom c·ª•m cao (clustering ‚âà {avg_clustering:.4f})\")\n",
    "    print(f\"     - ƒêi·ªÅu n√†y cho th·∫•y s·ª± t·ªìn t·∫°i c·ªßa c√°c \\\"nh√≥m b·∫°n\\\" ch·∫∑t ch·∫Ω\")\n",
    "else:\n",
    "    print(f\"\\n  ‚ûú K·∫æT LU·∫¨N: M·∫°ng c√≥ t√≠nh ch·∫•t kh√¥ng ho√†n to√†n Small World\")\n",
    "\n",
    "print(\"\\n[2. THU·∫¨T TO√ÅN X·∫æP H·∫†NG (RANKING ALGORITHMS)]\")\n",
    "print(f\"  ‚úì PageRank: X√°c ƒë·ªãnh c√°c node c√≥ ·∫£nh h∆∞·ªüng cao\")\n",
    "print(f\"  ‚úì Degree Centrality: X√°c ƒë·ªãnh c√°c hub tr·ª±c ti·∫øp k·∫øt n·ªëi\")\n",
    "print(f\"  ‚úì Betweenness Centrality: X√°c ƒë·ªãnh nh·ªØng ng∆∞·ªùi \\\"c·∫ßu n·ªëi\\\"\")\n",
    "print(f\"  ‚úì Closeness Centrality: X√°c ƒë·ªãnh nh·ªØng ng∆∞·ªùi \\\"trung t√¢m\\\"\")\n",
    "print(f\"\\n  ‚ûú Top node theo PageRank:\")\n",
    "\n",
    "if top_pagerank:\n",
    "    top_node = top_pagerank[0]\n",
    "    top_title = nodes_df[nodes_df['id'] == top_node[0]]['title'].values[0] if top_node[0] in nodes_df['id'].values else top_node[0]\n",
    "    top_type = nodes_df[nodes_df['id'] == top_node[0]]['type'].values[0] if top_node[0] in nodes_df['id'].values else 'unknown'\n",
    "    print(f\"     - {top_title} [{top_type}] (Score: {top_node[1]:.6f})\")\n",
    "\n",
    "print(\"\\n[3. PH√ÅT HI·ªÜN C·ªòNG ƒê·ªíNG (COMMUNITY DETECTION)]\")\n",
    "print(f\"  ‚úì S·ªë c·ªông ƒë·ªìng ph√°t hi·ªán: {len(communities_louvain)}\")\n",
    "print(f\"  ‚úì Modularity Score: {modularity_louvain:.6f}\")\n",
    "print(f\"  ‚úì K√≠ch th∆∞·ªõc c·ªông ƒë·ªìng t·ª´ {min(sizes)} ƒë·∫øn {max(sizes)} nodes\")\n",
    "\n",
    "print(f\"\\n  ‚ûú √ù NGHƒ®A:\")\n",
    "print(f\"     - M·∫°ng Alumni t·ª± t·ªï ch·ª©c th√†nh {len(communities_louvain)} c·ªông ƒë·ªìng\")\n",
    "print(f\"     - M·ªói c·ªông ƒë·ªìng ƒë·∫°i di·ªán m·ªôt \\\"nh√°nh\\\" c·ªßa m·∫°ng v·ªõi k·∫øt n·ªëi ch·∫∑t ch·∫Ω\")\n",
    "if modularity_louvain > 0.3:\n",
    "    print(f\"     - Modularity cao ({modularity_louvain:.4f}) ‚Üí C·ªông ƒë·ªìng r√µ r√†ng, t√°ch bi·ªát\")\n",
    "elif modularity_louvain > 0.1:\n",
    "    print(f\"     - Modularity trung b√¨nh ({modularity_louvain:.4f}) ‚Üí C·ªông ƒë·ªìng y·∫øu, nhi·ªÅu li√™n k·∫øt xuy√™n\")\n",
    "else:\n",
    "    print(f\"     - Modularity th·∫•p ({modularity_louvain:.4f}) ‚Üí M·∫°ng li√™n th√¥ng t·ªët, √≠t t√°ch bi·ªát\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì PH√ÇN T√çCH HO√ÄN T·∫§T\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260465f",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ T√≥m T·∫Øt & K·∫øt Lu·∫≠n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9646ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√¨nh ·∫£nh h√≥a c·ªông ƒë·ªìng\n",
    "print(\"\\n[H√¨nh ·∫£nh h√≥a C·ªòNG ƒê·ªíNG]\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bi·ªÉu ƒë·ªì k√≠ch th∆∞·ªõc c·ªông ƒë·ªìng\n",
    "comm_sizes = [stat['size'] for stat in community_stats]\n",
    "comm_labels = [f\"Community {i+1}\" for i in range(len(community_stats))]\n",
    "colors_comm = plt.cm.Set3(np.linspace(0, 1, len(comm_sizes)))\n",
    "\n",
    "axes[0].bar(range(len(comm_sizes)), comm_sizes, color=colors_comm)\n",
    "axes[0].set_xticks(range(len(comm_sizes)))\n",
    "axes[0].set_xticklabels(comm_labels, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('S·ªë L∆∞·ª£ng Nodes', fontsize=11)\n",
    "axes[0].set_title('K√≠ch Th∆∞·ªõc C√°c C·ªông ƒê·ªìng', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ph√¢n b·ªë lo·∫°i nodes trong m·ªói c·ªông ƒë·ªìng\n",
    "node_type_distribution = {}\n",
    "for node_type in nodes_df['type'].unique():\n",
    "    node_type_distribution[node_type] = [stat['node_types'].get(node_type, 0) for stat in community_stats]\n",
    "\n",
    "x = np.arange(len(comm_labels))\n",
    "width = 0.2\n",
    "colors_types = {'person': '#FF6B6B', 'university': '#4ECDC4', 'country': '#95E1D3', 'career': '#F38181'}\n",
    "\n",
    "for i, (node_type, values) in enumerate(node_type_distribution.items()):\n",
    "    offset = (i - len(node_type_distribution) / 2) * width\n",
    "    axes[1].bar(x + offset, values, width, label=node_type, color=colors_types.get(node_type, '#999999'))\n",
    "\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(comm_labels, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('S·ªë L∆∞·ª£ng Nodes', fontsize=11)\n",
    "axes[1].set_title('Ph√¢n B·ªë Lo·∫°i Nodes Theo C·ªông ƒê·ªìng', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graph_out/community_detection.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì L∆∞u: graph_out/community_detection.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
