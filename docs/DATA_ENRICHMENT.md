# üìä H∆∞·ªõng D·∫´n L√†m Gi√†u D·ªØ Li·ªáu ƒê·ªì Th·ªã - Data Enrichment Guide

## üéØ T·ªïng Quan

D·ª± √°n n√†y x√¢y d·ª±ng m·ªôt h·ªá th·ªëng to√†n di·ªán ƒë·ªÉ **l√†m gi√†u d·ªØ li·ªáu ƒë·ªì th·ªã** (Graph Data Enrichment) v·ªÅ c·ª±u sinh vi√™n v√† ƒë·∫°i h·ªçc qu·ªëc t·∫ø. H·ªá th·ªëng s·ª≠ d·ª•ng:

- **Named Entity Recognition (NER)** - Nh·∫≠n d·∫°ng th·ª±c th·ªÉ (Career, Country)
- **Relationship Extraction** - Tr√≠ch xu·∫•t m·ªëi quan h·ªá gi·ªØa c√°c th·ª±c th·ªÉ
- **Knowledge Graph Construction** - X√¢y d·ª±ng ƒë·ªì th·ªã tri th·ª©c
- **Data Quality Validation** - Ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu

---

## üìÅ C·∫•u Tr√∫c T·ªáp Tin

```
university-alumni-graph-main/
‚îú‚îÄ‚îÄ data_enrichment.py                 # Module l√†m gi√†u d·ªØ li·ªáu ch√≠nh
‚îú‚îÄ‚îÄ advanced_ner.py                    # Module NER n√¢ng cao
‚îú‚îÄ‚îÄ data_enrichment_demo.ipynb         # Jupyter notebook demo
‚îú‚îÄ‚îÄ requirements.txt                   # Th∆∞ vi·ªán c·∫ßn thi·∫øt
‚îú‚îÄ‚îÄ graph_out/                         # Th∆∞ m·ª•c k·∫øt qu·∫£
‚îÇ   ‚îú‚îÄ‚îÄ node_details.json             # D·ªØ li·ªáu node g·ªëc
‚îÇ   ‚îú‚îÄ‚îÄ nodes_enriched.json           # Nodes sau khi l√†m gi√†u
‚îÇ   ‚îú‚îÄ‚îÄ nodes_careers.json            # Nodes v·ªÅ ngh·ªÅ nghi·ªáp
‚îÇ   ‚îú‚îÄ‚îÄ nodes_countries.json          # Nodes v·ªÅ qu·ªëc gia
‚îÇ   ‚îú‚îÄ‚îÄ edges_enrichment.json         # Edges m·ªõi t·∫°o
‚îÇ   ‚îú‚îÄ‚îÄ ner_results.json              # K·∫øt qu·∫£ NER
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ DATA_ENRICHMENT.md            # H∆∞·ªõng d·∫´n n√†y
    ‚îî‚îÄ‚îÄ ...
```

---

## üöÄ C√†i ƒê·∫∑t v√† S·ª≠ D·ª•ng

### 1. C√†i ƒê·∫∑t Th∆∞ Vi·ªán

```bash
# C√†i ƒë·∫∑t t·∫•t c·∫£ dependencies
pip install -r requirements.txt

# (Optional) C√†i spaCy model cho ti·∫øng Vi·ªát
python -m spacy download vi_core_news_sm

# (Optional) C√†i spaCy model cho ti·∫øng Anh
python -m spacy download en_core_web_sm
```

### 2. Ch·∫°y Module L√†m Gi√†u D·ªØ Li·ªáu

#### C√°ch 1: Ch·∫°y t·ª´ Command Line

```bash
# Ch·∫°y v·ªõi file m·∫∑c ƒë·ªãnh (graph_out/node_details.json)
python data_enrichment.py

# Ch·∫°y v·ªõi file t√πy ch·ªânh
python data_enrichment.py --input path/to/node_details.json --output path/to/output_dir
```

#### C√°ch 2: S·ª≠ D·ª•ng t·ª´ Code Python

```python
from data_enrichment import GraphEnricher

# Kh·ªüi t·∫°o enricher
enricher = GraphEnricher("graph_out/node_details.json")

# Ch·∫°y enrichment
all_nodes, new_edges = enricher.save_enriched_graph("graph_out")

# In th·ªëng k√™
from data_enrichment import print_enrichment_stats
print_enrichment_stats(all_nodes, new_edges)
```

#### C√°ch 3: S·ª≠ D·ª•ng Jupyter Notebook

```bash
# M·ªü notebook
jupyter notebook data_enrichment_demo.ipynb

# Ho·∫∑c trong VS Code, m·ªü file .ipynb tr·ª±c ti·∫øp
```

---

## üìä C√°c Th√†nh Ph·∫ßn Ch√≠nh

### A. CountryDatabase (C∆° s·ªü d·ªØ li·ªáu qu·ªëc gia)

Ch·ª©a danh s√°ch 40+ qu·ªëc gia v√† c√°ch vi·∫øt ti·∫øng Vi·ªát.

```python
from data_enrichment import CountryDatabase

# Tr√≠ch xu·∫•t qu·ªëc gia t·ª´ text
countries = CountryDatabase.extract_countries(
    "T·ªïng th·ªëng M·ªπ sinh t·∫°i New York"
)
# Output: ['M·ªπ']
```

### B. CareerDatabase (C∆° s·ªü d·ªØ li·ªáu ngh·ªÅ nghi·ªáp)

Ch·ª©a 50+ lo·∫°i ngh·ªÅ nghi·ªáp v·ªõi d·ªãch ti·∫øng Anh.

```python
from data_enrichment import CareerDatabase

# Tr√≠ch xu·∫•t ngh·ªÅ nghi·ªáp t·ª´ text
careers = CareerDatabase.extract_careers_from_text(
    "Gi√°o s∆∞ ƒê·∫°i h·ªçc Harvard"
)
# Output: ['Gi√°o s∆∞']

# Tr√≠ch xu·∫•t t·ª´ properties
properties = {"Ch·ª©c v·ª•": "Ph√≥ Gi√°m ƒë·ªëc"}
careers = CareerDatabase.extract_careers(properties)
# Output: [('Ph√≥ Gi√°m ƒë·ªëc', 'Executive')]
```

### C. EntityRelationshipExtractor (Tr√≠ch xu·∫•t Th·ª±c th·ªÉ - M·ªëi quan h·ªá)

```python
from data_enrichment import EntityRelationshipExtractor

extractor = EntityRelationshipExtractor()

# Tr√≠ch xu·∫•t t·ª´ properties c·ªßa node
properties = {
    "Sinh": "1951, Vi·ªát Nam",
    "M·∫•t": "2020, Ph√°p",
    "Ch·ª©c v·ª•": "Gi√°o s∆∞"
}

result = extractor.extract_from_properties("Ng∆∞·ªùi A", properties)
# Output:
# {
#   "person": "Ng∆∞·ªùi A",
#   "careers": [("Gi√°o s∆∞", "Academic")],
#   "countries": ["Vi·ªát Nam", "Ph√°p"],
#   "birth_country": "Vi·ªát Nam",
#   "death_country": "Ph√°p"
# }
```

### D. GraphEnricher (L√†m gi√†u ƒê·ªì th·ªã)

```python
from data_enrichment import GraphEnricher

# Kh·ªüi t·∫°o
enricher = GraphEnricher("graph_out/node_details.json")

# Ch·∫°y enrichment
all_nodes, new_edges = enricher.extract_all_enrichments()

# L∆∞u k·∫øt qu·∫£
enricher.save_enriched_graph("graph_out")
```

---

## üîç K·ªπ Thu·∫≠t Nh·∫≠n D·∫°ng Th·ª±c Th·ªÉ

### 1. Rule-Based Extraction (C∆° b·∫£n)

- T√¨m ki·∫øm pattern trong text
- So kh·ªõp v·ªõi danh s√°ch t·ª´ v·ª±ng
- Nhanh, nh∆∞ng ƒë·ªô ch√≠nh x√°c h·∫°n ch·∫ø

```python
# ƒê∆∞·ª£c s·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh trong data_enrichment.py
text = "Gi√°o s∆∞ Ph·∫°m VƒÉn A sinh nƒÉm 1950 t·∫°i H√† N·ªôi"

countries = CountryDatabase.extract_countries(text)
# ['Vi·ªát Nam']

careers = CareerDatabase.extract_careers_from_text(text)
# ['Gi√°o s∆∞']
```

### 2. spaCy NER (M√¢u h∆°n)

- S·ª≠ d·ª•ng pre-trained models
- Nh·∫≠n d·∫°ng PERSON, ORG, GPE, etc.
- C·∫ßn c√†i `python -m spacy download vi_core_news_sm`

```python
from advanced_ner import AdvancedNER

ner = AdvancedNER()

entities = ner.extract_entities_spacy(
    "Gi√°o s∆∞ Ph·∫°m VƒÉn A l√†m vi·ªác t·∫°i ƒê·∫°i h·ªçc Qu·ªëc gia H√† N·ªôi"
)
# Output:
# {
#   'PERSON': ['Ph·∫°m VƒÉn A'],
#   'ORG': ['ƒê·∫°i h·ªçc Qu·ªëc gia H√† N·ªôi']
# }
```

### 3. Transformer-Based NER (T·ªët nh·∫•t)

- S·ª≠ d·ª•ng deep learning models (BERT, RoBERTa, etc.)
- ƒê·ªô ch√≠nh x√°c cao
- Ch·∫≠m h∆°n, c·∫ßn GPU

```python
from advanced_ner import AdvancedNER

ner = AdvancedNER(model_name="xlm-roberta-large-finetuned-conll03-english")

entities = ner.extract_entities_transformers(
    "Albert Einstein was born in Germany"
)
```

---

## üîó Tr√≠ch Xu·∫•t M·ªëi Quan H·ªá

### Relationship Types (C√°c lo·∫°i m·ªëi quan h·ªá)

| Type | M√¥ T·∫£ | V√≠ D·ª• |
|------|-------|-------|
| HAS_CAREER | Ng∆∞·ªùi c√≥ ngh·ªÅ | Ng∆∞·ªùi A -> Gi√°o s∆∞ |
| ASSOCIATED_WITH_COUNTRY | Li√™n k·∫øt v·ªõi qu·ªëc gia | Ng∆∞·ªùi A -> Vi·ªát Nam |
| BORN_IN | Sinh t·∫°i | Ng∆∞·ªùi A -> Vi·ªát Nam |
| DIED_IN | M·∫•t t·∫°i | Ng∆∞·ªùi A -> Ph√°p |
| WORKS_IN | L√†m vi·ªác t·∫°i | Ng∆∞·ªùi A -> M·ªπ |
| EDUCATED_AT | H·ªçc t·∫°i | Ng∆∞·ªùi A -> Harvard |

### Pattern-Based Extraction

```python
from advanced_ner import RelationshipExtractor

text = "Gi√°o s∆∞ Ph·∫°m VƒÉn A sinh t·∫°i H√† N·ªôi, m·∫•t t·∫°i Paris"

relationships = RelationshipExtractor.extract_relationships(text, {})
# Output:
# [
#   {"type": "BORN_IN", "entity": "H√† N·ªôi", "confidence": 0.8},
#   {"type": "DIED_IN", "entity": "Paris", "confidence": 0.8}
# ]
```

---

## üìà Ch·∫•t L∆∞·ª£ng v√† Validation

### Quality Metrics

```python
from advanced_ner import EnrichmentQualityMetrics

# Coverage metrics
coverage = EnrichmentQualityMetrics.calculate_coverage(
    enriched_nodes, original_nodes
)
# Output:
# {
#   "original_nodes": 1000,
#   "enriched_nodes": 1350,
#   "growth_rate": 0.35,
#   "coverage_percentage": 135.0
# }

# Extraction quality
quality = EnrichmentQualityMetrics.calculate_extraction_quality(extractions)

# Relationship validation
validation = EnrichmentQualityMetrics.validate_relationships(
    relationships, all_node_titles
)
```

### Data Quality Checks

1. **Duplicate Detection** - Ki·ªÉm tra node tr√πng l·∫∑p
2. **Missing Fields** - Ki·ªÉm tra tr∆∞·ªùng b·∫Øt bu·ªôc
3. **Orphaned Edges** - Ki·ªÉm tra edge kh√¥ng c√≥ endpoint
4. **Coverage Rate** - T·ª∑ l·ªá nodes c√≥ enrichment
5. **Confidence Scores** - ƒêi·ªÉm tin c·∫≠y c·ªßa extractions

---

## üíæ Output Files

### 1. nodes_enriched.json
T·∫•t c·∫£ nodes (original + career + country) v·ªõi metadata

```json
{
  "title": "Ph·∫°m VƒÉn A",
  "type": "person",
  "link": "https://vi.wikipedia.org/wiki/Ph·∫°m_VƒÉn_A",
  "related": [],
  "properties": {
    "Sinh": "1950, H√† N·ªôi",
    "M·∫•t": "2020, Paris"
  }
}
```

### 2. edges_enrichment.json
T·∫•t c·∫£ edges l√†m gi√†u

```json
{
  "source": "Ph·∫°m VƒÉn A",
  "target": "Gi√°o s∆∞",
  "type": "HAS_CAREER",
  "weight": 1
}
```

### 3. nodes_careers.json
Ch·ªâ career nodes

```json
{
  "title": "Gi√°o s∆∞",
  "type": "career",
  "link": "https://en.wikipedia.org/wiki/Professor",
  "properties": {"category": "Occupation"}
}
```

### 4. nodes_countries.json
Ch·ªâ country nodes

```json
{
  "title": "Vi·ªát Nam",
  "type": "country",
  "link": "https://en.wikipedia.org/wiki/Vietnam",
  "properties": {
    "english_name": "Vietnam",
    "country_code": "VN",
    "category": "Geographic"
  }
}
```

### 5. ner_results.json
Chi ti·∫øt k·∫øt qu·∫£ NER cho m·ªói person

```json
{
  "person": "Ph·∫°m VƒÉn A",
  "careers": ["Gi√°o s∆∞", "Nh√† khoa h·ªçc"],
  "countries": ["Vi·ªát Nam", "Ph√°p"]
}
```

---

## üîß Configuration & Customization

### 1. Th√™m qu·ªëc gia m·ªõi

```python
# Trong data_enrichment.py, th√™m v√†o CountryDatabase.COUNTRIES
COUNTRIES = {
    ...
    "Hy L·∫°p": {"en": "Greece", "code": "GR"},
    ...
}
```

### 2. Th√™m ngh·ªÅ nghi·ªáp m·ªõi

```python
# Trong data_enrichment.py, th√™m v√†o CareerDatabase.CAREERS
CAREERS = {
    ...
    "Nh√† khoa h·ªçc m√°y t√≠nh": "Computer Scientist",
    ...
}
```

### 3. ƒêi·ªÅu ch·ªânh Extraction Logic

```python
# T·∫°o custom extractor
class CustomExtractor(EntityRelationshipExtractor):
    def extract_from_properties(self, person_title, properties):
        result = super().extract_from_properties(person_title, properties)
        
        # Th√™m logic t√πy ch·ªânh
        if "Custom_Field" in properties:
            result["custom_data"] = properties["Custom_Field"]
        
        return result
```

---

## üìä Jupyter Notebook Walkthrough

Notebook `data_enrichment_demo.ipynb` g·ªìm 8 b∆∞·ªõc:

1. **Import Libraries** - C√†i ƒë·∫∑t th∆∞ vi·ªán
2. **Load Data** - T·∫£i JSON nodes
3. **Text Preprocessing** - Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
4. **NER** - Nh·∫≠n d·∫°ng th·ª±c th·ªÉ
5. **Relationship Extraction** - Tr√≠ch xu·∫•t m·ªëi quan h·ªá
6. **Create Nodes** - T·∫°o nodes m·ªõi
7. **Build Graph** - X√¢y d·ª±ng ƒë·ªì th·ªã
8. **Export & Validate** - Xu·∫•t v√† ki·ªÉm tra

Ch·∫°y t·ª´ng cell ƒë·ªÉ th·∫•y k·∫øt qu·∫£ t·ª´ng b∆∞·ªõc.

---

## üéì V√≠ D·ª• S·ª≠ D·ª•ng

### V√≠ d·ª• 1: Enrichment ƒê∆°n Gi·∫£n

```python
from data_enrichment import GraphEnricher

enricher = GraphEnricher("graph_out/node_details.json")
nodes, edges = enricher.extract_all_enrichments()

print(f"Nodes: {len(nodes)}")
print(f"Edges: {len(edges)}")

enricher.save_enriched_graph("graph_out")
```

### V√≠ d·ª• 2: Advanced NER

```python
from advanced_ner import AdvancedNER

ner = AdvancedNER()

text = """
Gi√°o s∆∞ Ph·∫°m VƒÉn A, ng∆∞·ªùi s√°ng l·∫≠p ƒê·∫°i h·ªçc Qu·ªëc gia H√† N·ªôi,
sinh nƒÉm 1950 t·∫°i H√† N·ªôi, Vi·ªát Nam. √îng t·ªët nghi·ªáp t·∫°i 
ƒê·∫°i h·ªçc Cambridge, Anh v√† l√†m vi·ªác t·∫°i M·ªπ t·ª´ 1975-1990.
"""

# spaCy extraction
print(ner.extract_entities_spacy(text))

# Transformer extraction
print(ner.extract_entities_transformers(text))
```

### V√≠ d·ª• 3: Relationship Extraction

```python
from advanced_ner import RelationshipExtractor

text = "T·ªïng th·ªëng H·ªì Ch√≠ Minh sinh nƒÉm 1890 t·∫°i Th√°i B√¨nh"

relationships = RelationshipExtractor.extract_relationships(text, {})

for rel in relationships:
    print(f"{rel['type']}: {rel['entity']} (confidence: {rel['confidence']})")
```

---

## üö® Troubleshooting

### L·ªói: "ModuleNotFoundError: No module named 'spacy'"

```bash
pip install spacy
python -m spacy download vi_core_news_sm
```

### L·ªói: "FileNotFoundError: graph_out/node_details.json"

ƒê·∫£m b·∫£o b·∫°n ƒë√£ ch·∫°y `run_pipeline_clean.py` tr∆∞·ªõc:

```bash
python run_pipeline_clean.py
```

### L·ªói: "CUDA out of memory"

N·∫øu ch·∫°y transformers models:

```python
# Gi·∫£m batch size ho·∫∑c s·ª≠ d·ª•ng CPU
import torch
torch.cuda.empty_cache()

# Ho·∫∑c s·ª≠ d·ª•ng CPU
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
```

### ƒê·ªô ch√≠nh x√°c th·∫•p

- Th·ª≠ d√πng advanced NER models thay v√¨ rule-based
- Th√™m nhi·ªÅu v√≠ d·ª• training data
- ƒêi·ªÅu ch·ªânh confidence thresholds

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

### Papers & Concepts
- **Named Entity Recognition**: Named Entity Recognition using BERT
- **Knowledge Graph Construction**: Knowledge Graph Completion
- **Relationship Extraction**: Distant Supervision for Relation Extraction

### Libraries
- [spaCy](https://spacy.io) - Industrial-grade NLP
- [Transformers (Hugging Face)](https://huggingface.co/transformers/) - State-of-the-art models
- [NetworkX](https://networkx.org) - Graph analysis
- [pandas](https://pandas.pydata.org) - Data manipulation

---

## ü§ù ƒê√≥ng G√≥p

ƒê·ªÉ c·∫£i thi·ªán d·ª± √°n:

1. M·ªü issue tr√™n GitHub
2. T·∫°o pull request v·ªõi c·∫£i thi·ªán
3. Th√™m test cases cho c√°c lo·∫°i d·ªØ li·ªáu m·ªõi

---

## üìù Ghi Ch√∫

- Data quality ph·ª• thu·ªôc v√†o ch·∫•t l∆∞·ª£ng Wikipedia data g·ªëc
- M·ªôt s·ªë ng∆∞·ªùi n·ªïi ti·∫øng c√≥ th√¥ng tin kh√¥ng ƒë·∫ßy ƒë·ªß
- K·∫øt qu·∫£ t·ªët nh·∫•t khi k·∫øt h·ª£p nhi·ªÅu NER methods
- Th∆∞·ªùng xuy√™n validate results v·ªõi domain experts

---

**Last Updated**: December 2025
**Version**: 1.0
**Status**: Active Development
