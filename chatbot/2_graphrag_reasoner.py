# -*- coding: utf-8 -*-
"""
2_graphrag_reasoner.py
Triá»ƒn khai GraphRAG vÃ  suy luáº­n Multi-hop trÃªn Ä‘á»“ thá»‹
"""
from typing import List, Dict, Optional
import importlib

KnowledgeGraph = None  # Sáº½ Ä‘Æ°á»£c import khi cáº§n

class GraphRAGReasoner:
    """Triá»ƒn khai GraphRAG + Multi-hop Reasoning"""
    
    def __init__(self, kg):
        self.kg = kg
    
    def _normalize_text(self, text: str) -> str:
        """Chuáº©n hÃ³a Ä‘á»ƒ so khá»›p tá»± do trong cÃ¢u há»i"""
        import unicodedata
        import re
        s = unicodedata.normalize('NFD', text)
        s = ''.join(ch for ch in s if unicodedata.category(ch) != 'Mn')
        s = s.lower().replace('_', ' ').replace('-', ' ')
        s = re.sub(r"[^a-z0-9 ]+", " ", s)
        return " ".join(s.split())
    
    def retrieve_context(self, query: str, max_hops: int = 2) -> str:
        """
        Truy xuáº¥t ngá»¯ cáº£nh tá»« Knowledge Graph (GraphRAG)
        - TÃ­ch xuáº¥t entities tá»« query
        - Láº¥y thÃ´ng tin tá»« Ä‘á»“ thá»‹
        """
        entities = self._extract_entities(query)
        
        if not entities:
            return "KhÃ´ng tÃ¬m tháº¥y thá»±c thá»ƒ nÃ o trong Ä‘á»“ thá»‹."
        
        context_parts = ["=== NGá»® Cáº¢NH Tá»ª KNOWLEDGE GRAPH ===\n"]
        found_entities = []
        missing_entities = []
        
        for entity in entities[:5]:
            node_id = self.kg.title_to_node.get(entity)
            if node_id:
                found_entities.append(entity)
                info = self.kg.get_node_info(node_id)
                context_parts.append(self._format_node_info(info))
                
                # ThÃªm thÃ´ng tin vá» cÃ¡c cáº¡nh/quan há»‡/káº¿t ná»‘i
                neighbors = self.kg.get_neighbors(node_id)
                if neighbors:
                    context_parts.append(f"  ðŸ”— CÃ¡c cáº¡nh káº¿t ná»‘i ({len(neighbors)} quan há»‡):")
                    for n in neighbors[:5]:
                        context_parts.append(f"     â€¢ {n['title']} [quan há»‡: {n['relation']}]")
            else:
                missing_entities.append(entity)
        
        # ThÃ´ng bÃ¡o vá» entities khÃ´ng tÃ¬m tháº¥y
        if missing_entities:
            context_parts.append(f"\nâš ï¸  KhÃ´ng tÃ¬m tháº¥y cÃ¡c thá»±c thá»ƒ sau trong Ä‘á»“ thá»‹: {', '.join(missing_entities)}")
        
        return "\n".join(context_parts)
    
    def _extract_entities(self, query: str) -> List[str]:
        """TrÃ­ch xuáº¥t tÃªn entities tá»« query"""
        entities = []
        norm_query = self._normalize_text(query)
        query_lower = norm_query
        
        # Keywords khÃ´ng pháº£i entities (CHá»ˆ skip khi Ä‘á»©ng Ä‘á»™c láº­p)
        skip_keywords = ['trÆ°á»ng', 'há»c', 'nhá»¯ng', 'nÃ o', 'cÆ¡', 'cÃ³', 'khÃ´ng', 'vÃ ', 'hay',
                        'Ä‘Æ°á»£c', 'cÃ¹ng', 'liÃªn quan', 'káº¿t ná»‘i', 'má»‘i', 'ngÆ°á»i', 'ai', 'lÃ ', 'gÃ¬',
                        'nÆ¡i', 'Ä‘Ã¢u', 'bao nhiÃªu', 'máº¥y', 'bao giá»', 'khi nÃ o', 'tÃ¬m', 'láº¥y', 'sinh', 'vien']
        
        for title in self.kg.title_to_node.keys():
            title_normalized = self._normalize_text(title)
            # Chá»‰ láº¥y náº¿u title xuáº¥t hiá»‡n trong query
            # KHÃ”NG skip "Ä‘áº¡i há»c" vÃ¬ nÃ³ lÃ  part cá»§a tÃªn trÆ°á»ng (Äáº¡i há»c Harvard, Äáº¡i há»c Stanford...)
            if title_normalized in query_lower and title_normalized not in skip_keywords:
                # Kiá»ƒm tra Ä‘Ã³ lÃ  person, university, hoáº·c country node
                node_id = self.kg.title_to_node[title]
                node_type = self.kg.node_types.get(node_id, '').lower()
                if node_type in ['person', 'university', 'country']:
                    entities.append(title)
        
        entities.sort(key=len, reverse=True)  # Æ¯u tiÃªn tÃªn dÃ i hÆ¡n
        return entities
    
    def _format_node_info(self, info: Dict) -> str:
        """Format thÃ´ng tin nÃºt vá»›i mÃ´ táº£ rÃµ rÃ ng vá» cáº¡nh/káº¿t ná»‘i"""
        s = f"\nðŸ“Œ {info['title']} ({info['type']})\n"
        s += f"   Sá»‘ cáº¡nh vÃ o (in-degree): {info['in_degree']}, Sá»‘ cáº¡nh ra (out-degree): {info['out_degree']}"
        s += f"\n   ðŸ’¡ Giáº£i thÃ­ch: Node nÃ y cÃ³ {info['in_degree'] + info['out_degree']} káº¿t ná»‘i/quan há»‡ trong Ä‘á»“ thá»‹"
        # ThÃªm properties náº¿u cÃ³
        props = info.get('properties')
        if props:
            if isinstance(props, dict):
                for k, v in props.items():
                    s += f"\n   â€¢ {k}: {v}"
            else:
                s += f"\n   â€¢ Properties: {props}"
        return s
    
    def check_connection(self, entity1: str, entity2: str, max_hops: int = 3) -> Dict:
        """Kiá»ƒm tra káº¿t ná»‘i giá»¯a 2 entities qua cÃ¡c cáº¡nh/quan há»‡ (Multi-hop Reasoning)"""
        node1 = self.kg.title_to_node.get(entity1)
        node2 = self.kg.title_to_node.get(entity2)
        
        # Kiá»ƒm tra entity cÃ³ tá»“n táº¡i khÃ´ng
        missing = []
        if not node1:
            missing.append(entity1)
        if not node2:
            missing.append(entity2)
        
        if missing:
            return {
                'connected': False, 
                'reason': f'KhÃ´ng tÃ¬m tháº¥y cÃ¡c thá»±c thá»ƒ sau trong Ä‘á»“ thá»‹: {", ".join(missing)}',
                'missing_entities': missing
            }
        
        # DÃ¹ng Ä‘á»“ thá»‹ vÃ´ hÆ°á»›ng Ä‘á»ƒ báº¯t cáº£ trÆ°á»ng há»£p cáº¡nh chá»‰ cÃ³ má»™t chiá»u
        try:
            undirected = self.kg.G.to_undirected(as_view=True)
            import networkx as nx
            paths = list(nx.all_simple_paths(undirected, node1, node2, cutoff=max_hops))
        except Exception:
            paths = []
        
        if not paths:
            return {
                'connected': False, 
                'reason': f'KhÃ´ng cÃ³ Ä‘Æ°á»ng Ä‘i (chuá»—i cáº¡nh káº¿t ná»‘i) giá»¯a {entity1} vÃ  {entity2} trong {max_hops} bÆ°á»›c'
            }
        
        shortest = min(paths, key=len)
        path_desc = self._describe_path(shortest)
        
        return {
            'connected': True,
            'hops': len(shortest) - 1,
            'path': [self.kg.node_to_title[n] for n in shortest],
            'description': path_desc,
            'num_paths': len(paths),
            'explanation': f'TÃ¬m tháº¥y {len(paths)} Ä‘Æ°á»ng Ä‘i qua cÃ¡c cáº¡nh/quan há»‡. ÄÆ°á»ng ngáº¯n nháº¥t cÃ³ {len(shortest) - 1} cáº¡nh.'
        }
    
    def _describe_path(self, path: List[str]) -> str:
        """MÃ´ táº£ Ä‘Æ°á»ng Ä‘i qua cÃ¡c cáº¡nh/quan há»‡ dÆ°á»›i dáº¡ng text"""
        parts = []
        for i in range(len(path) - 1):
            src, dst = path[i], path[i + 1]
            src_title = self.kg.node_to_title[src]
            dst_title = self.kg.node_to_title[dst]
            # láº¥y relation cáº£ hai chiá»u náº¿u cÃ³ xung Ä‘á»™t/khÃ¡c nhau
            rels = []
            if self.kg.G.has_edge(src, dst):
                rels.append(self.kg.G[src][dst].get('relation'))
            if self.kg.G.has_edge(dst, src):
                rels.append(self.kg.G[dst][src].get('relation'))
            rels = [r for r in rels if r]
            if rels:
                rel_txt = ", ".join(sorted(set(rels)))
            else:
                rel_txt = "connected"
            parts.append(f"{src_title} --[cáº¡nh: {rel_txt}]--> {dst_title}")
        return " â†’ ".join(parts)
    
    def find_common_connections(self, entity1: str, entity2: str) -> Dict:
        """TÃ¬m Ä‘iá»ƒm chung giá»¯a 2 entities"""
        node1 = self.kg.title_to_node.get(entity1)
        node2 = self.kg.title_to_node.get(entity2)
        
        if not node1 or not node2:
            return {'common': [], 'count': 0}
        
        # Láº¥y lÃ¡ng giá»ng
        neighbors1 = set(self.kg.G.successors(node1)) | set(self.kg.G.predecessors(node1))
        neighbors2 = set(self.kg.G.successors(node2)) | set(self.kg.G.predecessors(node2))
        
        common = neighbors1.intersection(neighbors2)
        
        common_list = [{
            'title': self.kg.node_to_title[n],
            'type': self.kg.node_types[n]
        } for n in list(common)[:10]]
        
        return {'common': common_list, 'count': len(common)}
    
    def check_same_university(self, person1: str, person2: str) -> Dict:
        """Kiá»ƒm tra 2 ngÆ°á»i cÃ³ há»c cÃ¹ng trÆ°á»ng khÃ´ng qua cáº¡nh alumni_of"""
        node1 = self.kg.title_to_node.get(person1)
        node2 = self.kg.title_to_node.get(person2)
        
        # Kiá»ƒm tra entity cÃ³ tá»“n táº¡i khÃ´ng
        missing = []
        if not node1:
            missing.append(person1)
        if not node2:
            missing.append(person2)
        
        if missing:
            return {
                'answer': 'KHÃ”NG', 
                'reason': f'KhÃ´ng tÃ¬m tháº¥y cÃ¡c thá»±c thá»ƒ sau trong Ä‘á»“ thá»‹: {", ".join(missing)}',
                'missing_entities': missing
            }
        
        # Láº¥y universities
        unis1 = {n['id'] for n in self.kg.get_neighbors(node1, 'alumni_of')}
        unis2 = {n['id'] for n in self.kg.get_neighbors(node2, 'alumni_of')}
        
        common = unis1.intersection(unis2)
        
        if common:
            uni_names = [self.kg.node_to_title[u] for u in common]
            return {
                'answer': 'CÃ“',
                'universities': uni_names,
                'description': f"{person1} vÃ  {person2} cÃ¹ng há»c táº¡i: {', '.join(uni_names)}"
            }
        else:
            return {'answer': 'KHÃ”NG', 'description': f"{person1} vÃ  {person2} khÃ´ng há»c cÃ¹ng trÆ°á»ng"}

    def find_people_by_country_and_university(self, country_title: str, university_title: str, limit: int = 50) -> Dict:
        """TÃ¬m cÃ¡c person cÃ³ cáº¡nh from_country/born_in tá»›i country vÃ  alumni_of tá»›i university"""
        def _resolve(title: str):
            """TÃ¬m node id theo title vá»›i so khá»›p má»m (bá» dáº¥u, bá» gáº¡ch dÆ°á»›i/khoáº£ng tráº¯ng)"""
            import unicodedata, re
            def norm(s):
                s = unicodedata.normalize('NFD', s)
                s = ''.join(ch for ch in s if unicodedata.category(ch) != 'Mn')
                s = s.lower().replace('_', '').replace(' ', '')
                # loáº¡i tiá»n tá»‘ country Ä‘á»ƒ so khá»›p linh hoáº¡t (Trung Quoc vs country_Trung_Quoc)
                if s.startswith('country'):
                    s = s[len('country'):]
                s = re.sub(r"[^a-z0-9]+", "", s)
                return s

            t_lower = title.lower()
            # 1) So khá»›p exact (case-insensitive)
            for t, n in self.kg.title_to_node.items():
                if t.lower() == t_lower:
                    return n
            # 2) So khá»›p normalized (bá» dáº¥u, bá» _ vÃ  space)
            target = norm(title)
            for t, n in self.kg.title_to_node.items():
                if norm(t) == target:
                    return n
            return None

        country_id = _resolve(country_title)
        uni_id = _resolve(university_title)

        missing = []
        if not country_id:
            missing.append(country_title)
        if not uni_id:
            missing.append(university_title)
        if missing:
            return {'people': [], 'missing': missing}

        people = []
        for node, data in self.kg.G.nodes(data=True):
            if data.get('node_type') != 'person':
                continue
            # Kiá»ƒm tra cáº£ cáº¡nh ra vÃ  vÃ o (phÃ²ng khi dá»¯ liá»‡u Ä‘áº£o chiá»u)
            has_country = any(
                (nbr == country_id and self.kg.G[node][nbr].get('relation') in ['from_country', 'born_in'])
                for nbr in self.kg.G.successors(node)
            ) or any(
                (nbr == country_id and self.kg.G[nbr][node].get('relation') in ['from_country', 'born_in'])
                for nbr in self.kg.G.predecessors(node)
            )
            if not has_country:
                continue
            has_uni = any(
                (nbr == uni_id and self.kg.G[node][nbr].get('relation') == 'alumni_of')
                for nbr in self.kg.G.successors(node)
            ) or any(
                (nbr == uni_id and self.kg.G[nbr][node].get('relation') == 'alumni_of')
                for nbr in self.kg.G.predecessors(node)
            )
            if has_uni:
                people.append(data.get('title', node))
            if len(people) >= limit:
                break

        return {'people': people, 'missing': []}

    def find_people_by_university(self, university_title: str, limit: int = 100) -> Dict:
        """Liá»‡t kÃª cÃ¡c person cÃ³ cáº¡nh alumni_of tá»›i má»™t university"""
        def _resolve(title: str):
            import unicodedata, re
            def norm(s):
                s = unicodedata.normalize('NFD', s)
                s = ''.join(ch for ch in s if unicodedata.category(ch) != 'Mn')
                s = s.lower().replace('_', '').replace(' ', '')
                s = re.sub(r"[^a-z0-9]+", "", s)
                return s

            t_lower = title.lower()
            for t, n in self.kg.title_to_node.items():
                if t.lower() == t_lower:
                    return n
            target = norm(title)
            for t, n in self.kg.title_to_node.items():
                if norm(t) == target:
                    return n
            return None

        uni_id = _resolve(university_title)
        if not uni_id:
            return {'people': [], 'missing': [university_title]}

        people = []
        for node, data in self.kg.G.nodes(data=True):
            if data.get('node_type') != 'person':
                continue
            # alumni_of cÃ³ thá»ƒ lÃ  cáº¡nh ra (person -> uni) hoáº·c cáº¡nh vÃ o (uni -> person) tÃ¹y dá»¯ liá»‡u
            has_uni = any(
                (nbr == uni_id and self.kg.G[node][nbr].get('relation') == 'alumni_of')
                for nbr in self.kg.G.successors(node)
            ) or any(
                (nbr == uni_id and self.kg.G[nbr][node].get('relation') == 'alumni_of')
                for nbr in self.kg.G.predecessors(node)
            )
            if has_uni:
                people.append(data.get('title', node))
            if len(people) >= limit:
                break

        return {'people': people, 'missing': []}

    def find_people_by_country(self, country_title: str, limit: int = 100) -> Dict:
        """TÃ¬m cÃ¡c person cÃ³ cáº¡nh from_country/born_in tá»›i country (khÃ´ng yÃªu cáº§u trÆ°á»ng)"""
        country_id = None
        # DÃ¹ng cÃ¹ng _resolve cá»§a hÃ m trÃªn
        def _resolve(title: str):
            import unicodedata, re
            def norm(s):
                s = unicodedata.normalize('NFD', s)
                s = ''.join(ch for ch in s if unicodedata.category(ch) != 'Mn')
                s = s.lower().replace('_', '').replace(' ', '')
                s = re.sub(r"[^a-z0-9]+", "", s)
                return s
            t_lower = title.lower()
            for t, n in self.kg.title_to_node.items():
                if t.lower() == t_lower:
                    return n
            target = norm(title)
            for t, n in self.kg.title_to_node.items():
                if norm(t) == target:
                    return n
            return None

        country_id = _resolve(country_title)
        if not country_id:
            return {'people': [], 'missing': [country_title]}

        people = []
        for node, data in self.kg.G.nodes(data=True):
            if data.get('node_type') != 'person':
                continue
            has_country = any(
                (nbr == country_id and self.kg.G[node][nbr].get('relation') in ['from_country', 'born_in'])
                for nbr in self.kg.G.successors(node)
            ) or any(
                (nbr == country_id and self.kg.G[nbr][node].get('relation') in ['from_country', 'born_in'])
                for nbr in self.kg.G.predecessors(node)
            )
            if has_country:
                people.append(data.get('title', node))
            if len(people) >= limit:
                break

        return {'people': people, 'missing': []}


if __name__ == "__main__":
    KnowledgeGraph = importlib.import_module('1_knowledge_graph').KnowledgeGraph
    kg = KnowledgeGraph('graph_out/nodes_unified.csv', 'graph_out/edges_unified.csv')
    reasoner = GraphRAGReasoner(kg)
    
    # Test
    print("ðŸ§ª Test GraphRAG:")
    print(reasoner.retrieve_context("Barack Obama"))
